{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniocasseres/MVP2/blob/main/Antonio_MVP_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# MVP Sprint: Machine Learning & Analytics\n",
        "\n",
        "**Autor:** Antonio Casseres  \n",
        "**Data:** 28/09/2025  \n",
        "**Dataset:** [Heart Disease](https://archive.ics.uci.edu/dataset/45/heart+disease) - Cleveland Clinic Foundation\n",
        "\n",
        "---\n",
        "\n",
        "## Resumo\n",
        "\n",
        "Este projeto desenvolve um modelo de Machine Learning para classificação binária de doenças cardíacas utilizando dados clínicos autênticos do Cleveland Clinic Foundation. O modelo final baseado em Regressão Logística otimizada apresentou acurácia de 86.9% e ROC AUC de 0.9589 no conjunto de teste, demonstrando capacidade preditiva adequada para aplicações de apoio à decisão clínica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "problem_definition"
      },
      "source": [
        "## 1. Definição do Problema e Objetivo\n",
        "\n",
        "As doenças cardiovasculares representam uma das principais causas de mortalidade mundial, constituindo um problema de saúde pública significativo. A capacidade de prever a presença de doença cardíaca com base em dados clínicos é fundamental para a medicina preventiva e o planejamento de tratamentos.\n",
        "\n",
        "**Objetivo:** Desenvolver um modelo de Machine Learning para classificação binária que prediga a presença ou ausência de doença cardíaca em pacientes com base em atributos clínicos.\n",
        "\n",
        "**Tipo de Problema:** Classificação supervisionada binária  \n",
        "**Área de Aplicação:** Saúde e Medicina  \n",
        "**Justificativa:** Ferramenta de apoio à decisão clínica para identificação precoce de pacientes de risco\n",
        "\n",
        "**Premissas e Hipóteses:**\n",
        "- Os atributos clínicos selecionados possuem poder preditivo para diagnóstico de doença cardíaca\n",
        "- O dataset Cleveland é representativo da população de interesse\n",
        "- Modelos de Machine Learning podem capturar padrões complexos nos dados clínicos\n",
        "- A classificação binária é clinicamente relevante para triagem inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 2. Configuração do Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# === Importação das Bibliotecas ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_curve, auc,\n",
        "    accuracy_score, f1_score, roc_auc_score\n",
        ")\n",
        "\n",
        "# === Configurações ===\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "plt.style.use('seaborn-v0_8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading"
      },
      "source": [
        "## 3. Carregamento e Preparação dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "github_url = 'https://raw.githubusercontent.com/antoniocasseres/MVP2/main/cleveland_authentic.csv'\n",
        "\n",
        "# Carregar dados\n",
        "df = pd.read_csv(github_url)\n",
        "\n",
        "print(f\"URL: {github_url}\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Colunas: {list(df.columns)}\")\n",
        "\n",
        "# Verificar integridade dos dados\n",
        "print(f\"\\nVerificação de integridade:\")\n",
        "print(f\"Instâncias: {len(df)}\")\n",
        "print(f\"Features: {len(df.columns)-1} (padrão: 13 + 1 target)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_description"
      },
      "source": [
        "### 3.1 Descrição do Dataset\n",
        "\n",
        "O dataset Heart Disease Cleveland contém dados clínicos autênticos de 303 pacientes coletados pela Cleveland Clinic Foundation. Este dataset é amplamente utilizado na literatura de Machine Learning para problemas de classificação de doenças cardíacas.\n",
        "\n",
        "**Atributos (13 features + 1 target):**\n",
        "- **age:** idade em anos (numérica)\n",
        "- **sex:** sexo (1 = masculino, 0 = feminino)\n",
        "- **cp:** tipo de dor no peito (1-4, categórica)\n",
        "- **trestbps:** pressão arterial em repouso (mm Hg)\n",
        "- **chol:** colesterol sérico (mg/dl)\n",
        "- **fbs:** glicemia em jejum > 120 mg/dl (1 = verdadeiro, 0 = falso)\n",
        "- **restecg:** resultados eletrocardiográficos em repouso (0-2)\n",
        "- **thalach:** frequência cardíaca máxima alcançada\n",
        "- **exang:** angina induzida por exercício (1 = sim, 0 = não)\n",
        "- **oldpeak:** depressão ST induzida por exercício\n",
        "- **slope:** inclinação do segmento ST de pico de exercício (1-3)\n",
        "- **ca:** número de vasos principais coloridos por fluoroscopia (0-3)\n",
        "- **thal:** defeito talássico (3 = normal, 6 = defeito fixo, 7 = defeito reversível)\n",
        "- **num:** presença de doença cardíaca (0 = ausente, 1 = presente)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eda"
      },
      "source": [
        "### 3.2 Análise Exploratória dos Dados (EDA)\n",
        "\n",
        "A análise exploratória é conduzida para compreender as características dos dados, identificar padrões e orientar as decisões de pré-processamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "basic_info"
      },
      "outputs": [],
      "source": [
        "# === Informações Básicas ===\n",
        "print(\"=== INFORMAÇÕES BÁSICAS DO DATASET ===\")\n",
        "print(f\"Dimensões: {df.shape}\")\n",
        "print(f\"\\nTipos de dados:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(f\"\\nPrimeiras 5 linhas:\")\n",
        "display(df.head())\n",
        "\n",
        "print(f\"\\nEstatísticas descritivas:\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "missing_values"
      },
      "outputs": [],
      "source": [
        "# === Análise de Valores Ausentes ===\n",
        "print(\"=== VALORES AUSENTES ===\")\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Coluna': missing_data.index,\n",
        "    'Valores Ausentes': missing_data.values,\n",
        "    'Percentual (%)': missing_percent.values\n",
        "})\n",
        "\n",
        "missing_df = missing_df[missing_df['Valores Ausentes'] > 0].sort_values('Valores Ausentes', ascending=False)\n",
        "display(missing_df)\n",
        "\n",
        "if len(missing_df) == 0:\n",
        "    print(\"Não há valores ausentes no dataset.\")\n",
        "else:\n",
        "    print(f\"Total de colunas com valores ausentes: {len(missing_df)}\")\n",
        "    print(\"Valores ausentes são mínimos e serão tratados adequadamente no pré-processamento.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "target_distribution"
      },
      "outputs": [],
      "source": [
        "# === Distribuição da Variável Target ===\n",
        "print(\"=== DISTRIBUIÇÃO DA VARIÁVEL TARGET ===\")\n",
        "target_counts = df['num'].value_counts().sort_index()\n",
        "target_percent = df['num'].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "target_summary = pd.DataFrame({\n",
        "    'Classe': ['Sem Doença (0)', 'Com Doença (1)'],\n",
        "    'Contagem': target_counts.values,\n",
        "    'Percentual (%)': target_percent.values\n",
        "})\n",
        "\n",
        "display(target_summary)\n",
        "\n",
        "# Verificar balanceamento\n",
        "balance_ratio = min(target_counts.values) / max(target_counts.values)\n",
        "print(f\"\\nRatio de balanceamento: {balance_ratio:.3f}\")\n",
        "if balance_ratio >= 0.8:\n",
        "    print(\"Dataset bem balanceado - não requer técnicas de balanceamento\")\n",
        "elif balance_ratio >= 0.5:\n",
        "    print(\"Dataset moderadamente balanceado\")\n",
        "else:\n",
        "    print(\"Dataset desbalanceado - pode requerer técnicas de balanceamento\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualizations"
      },
      "outputs": [],
      "source": [
        "# === Visualizações da Análise Exploratória ===\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Análise Exploratória - Dataset Heart Disease (Autêntico UCI)', fontsize=16, y=1.02)\n",
        "\n",
        "# 1. Distribuição da variável target\n",
        "sns.countplot(data=df, x='num', ax=axes[0,0], palette='viridis')\n",
        "axes[0,0].set_title('Distribuição da Variável Target')\n",
        "axes[0,0].set_xlabel('0: Sem Doença | 1: Com Doença')\n",
        "\n",
        "# 2. Distribuição da idade por target\n",
        "sns.histplot(data=df, x='age', hue='num', kde=True, ax=axes[0,1], palette='plasma')\n",
        "axes[0,1].set_title('Distribuição da Idade por Diagnóstico')\n",
        "\n",
        "# 3. Tipo de dor no peito por target\n",
        "sns.countplot(data=df, x='cp', hue='num', ax=axes[0,2], palette='magma')\n",
        "axes[0,2].set_title('Tipo de Dor no Peito por Diagnóstico')\n",
        "\n",
        "# 4. Colesterol vs Frequência cardíaca máxima\n",
        "sns.scatterplot(data=df, x='chol', y='thalach', hue='num', ax=axes[1,0], alpha=0.7)\n",
        "axes[1,0].set_title('Colesterol vs Freq. Cardíaca Máxima')\n",
        "\n",
        "# 5. Matriz de correlação\n",
        "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'num']\n",
        "corr_matrix = df[numeric_cols].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
        "axes[1,1].set_title('Matriz de Correlação')\n",
        "\n",
        "# 6. Distribuição por sexo\n",
        "sns.countplot(data=df, x='sex', hue='num', ax=axes[1,2], palette='cividis')\n",
        "axes[1,2].set_title('Diagnóstico por Sexo')\n",
        "axes[1,2].set_xlabel('0: Feminino | 1: Masculino')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing"
      },
      "source": [
        "## 4. Pré-processamento e Divisão dos Dados\n",
        "\n",
        "Implementam-se pipelines robustos de pré-processamento para tratar adequadamente variáveis numéricas e categóricas, seguindo as melhores práticas de Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_split"
      },
      "outputs": [],
      "source": [
        "# === Preparação dos Dados ===\n",
        "print(\"=== PREPARAÇÃO DOS DADOS ===\")\n",
        "\n",
        "# Definir features e target\n",
        "X = df.drop(columns=['num'])\n",
        "y = df['num']\n",
        "\n",
        "# Identificar tipos de features baseado na documentação do dataset\n",
        "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "print(f\"Features numéricas ({len(numeric_features)}): {numeric_features}\")\n",
        "print(f\"Features categóricas ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "# Divisão estratificada em treino e teste (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nDivisão dos dados:\")\n",
        "print(f\"Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"Teste: {X_test.shape[0]} amostras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "# Verificar distribuição das classes nos conjuntos\n",
        "print(f\"\\nDistribuição das classes:\")\n",
        "print(f\"Treino - Classe 0: {(y_train==0).sum()}, Classe 1: {(y_train==1).sum()}\")\n",
        "print(f\"Teste - Classe 0: {(y_test==0).sum()}, Classe 1: {(y_test==1).sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocessing_pipelines"
      },
      "outputs": [],
      "source": [
        "# === Criação dos Pipelines de Pré-processamento ===\n",
        "print(\"=== PIPELINES DE PRÉ-PROCESSAMENTO ===\")\n",
        "\n",
        "# Pipeline para features numéricas\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Robustez a outliers\n",
        "    ('scaler', StandardScaler())  # Padronização\n",
        "])\n",
        "\n",
        "# Pipeline para features categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Moda\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding\n",
        "])\n",
        "\n",
        "# Pré-processador combinado\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Pipelines de pré-processamento criados:\")\n",
        "print(\"   • Numéricas: Imputação (mediana) + Padronização\")\n",
        "print(\"   • Categóricas: Imputação (moda) + One-Hot Encoding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "modeling"
      },
      "source": [
        "## 5. Modelagem e Avaliação Inicial\n",
        "\n",
        "Múltiplos algoritmos de classificação são avaliados usando validação cruzada estratificada para identificar os modelos mais promissores. A seleção de algoritmos considera diferentes abordagens: linear (Regressão Logística), ensemble (Random Forest), baseado em margem (SVM) e baseline (Dummy Classifier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_evaluation"
      },
      "outputs": [],
      "source": [
        "# === Definição e Avaliação dos Modelos ===\n",
        "print(\"=== AVALIAÇÃO INICIAL DOS MODELOS ===\")\n",
        "\n",
        "# Modelos a serem avaliados\n",
        "models = {\n",
        "    'Baseline (Dummy)': DummyClassifier(strategy='most_frequent', random_state=SEED),\n",
        "    'Regressão Logística': LogisticRegression(random_state=SEED, max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(random_state=SEED),\n",
        "    'SVM': SVC(probability=True, random_state=SEED)\n",
        "}\n",
        "\n",
        "# Configuração da validação cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "scoring = {'accuracy': 'accuracy', 'f1_weighted': 'f1_weighted', 'roc_auc': 'roc_auc'}\n",
        "\n",
        "# Avaliação dos modelos\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nAvaliando {name}...\")\n",
        "\n",
        "    # Criar pipeline completo\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Validação cruzada\n",
        "    cv_results = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring)\n",
        "\n",
        "    # Armazenar resultados\n",
        "    results.append({\n",
        "        'Modelo': name,\n",
        "        'Acurácia Média': np.mean(cv_results['test_accuracy']),\n",
        "        'Acurácia Std': np.std(cv_results['test_accuracy']),\n",
        "        'F1-Score Médio': np.mean(cv_results['test_f1_weighted']),\n",
        "        'ROC AUC Média': np.mean(cv_results['test_roc_auc']),\n",
        "        'ROC AUC Std': np.std(cv_results['test_roc_auc'])\n",
        "    })\n",
        "\n",
        "    print(f\"   Acurácia: {np.mean(cv_results['test_accuracy']):.4f} ± {np.std(cv_results['test_accuracy']):.4f}\")\n",
        "    print(f\"   ROC AUC: {np.mean(cv_results['test_roc_auc']):.4f} ± {np.std(cv_results['test_roc_auc']):.4f}\")\n",
        "\n",
        "# Criar DataFrame com resultados\n",
        "results_df = pd.DataFrame(results).sort_values('ROC AUC Média', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n=== TABELA COMPARATIVA DE MODELOS ===\")\n",
        "display(results_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyperparameter_optimization"
      },
      "source": [
        "## 6. Otimização de Hiperparâmetros\n",
        "\n",
        "A otimização de hiperparâmetros é realizada para os modelos mais promissores identificados na avaliação inicial, utilizando Grid Search para busca exaustiva em espaços menores e Randomized Search para espaços maiores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optimize_lr"
      },
      "outputs": [],
      "source": [
        "# === Otimização da Regressão Logística ===\n",
        "print(\"=== OTIMIZAÇÃO DA REGRESSÃO LOGÍSTICA ===\")\n",
        "\n",
        "# Pipeline para Regressão Logística\n",
        "lr_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=SEED, max_iter=2000))\n",
        "])\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "lr_param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__penalty': ['l1', 'l2'],\n",
        "    'classifier__solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "lr_grid_search = GridSearchCV(\n",
        "    lr_pipeline, lr_param_grid, cv=cv, scoring='roc_auc',\n",
        "    n_jobs=-1, verbose=1\n",
        ")\n",
        "\n",
        "print(\"Executando Grid Search...\")\n",
        "lr_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nOtimização concluída\")\n",
        "print(f\"Melhores hiperparâmetros: {lr_grid_search.best_params_}\")\n",
        "print(f\"Melhor ROC AUC (CV): {lr_grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optimize_rf"
      },
      "outputs": [],
      "source": [
        "# === Otimização do Random Forest ===\n",
        "print(\"=== OTIMIZAÇÃO DO RANDOM FOREST ===\")\n",
        "\n",
        "# Pipeline para Random Forest\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=SEED))\n",
        "])\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "rf_param_grid = {\n",
        "    'classifier__n_estimators': [50, 100, 200],\n",
        "    'classifier__max_depth': [3, 5, 10, None],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Randomized Search (mais eficiente para RF)\n",
        "rf_random_search = RandomizedSearchCV(\n",
        "    rf_pipeline, rf_param_grid, n_iter=20, cv=cv, scoring='roc_auc',\n",
        "    n_jobs=-1, random_state=SEED, verbose=1\n",
        ")\n",
        "\n",
        "print(\"Executando Randomized Search...\")\n",
        "rf_random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nOtimização concluída\")\n",
        "print(f\"Melhores hiperparâmetros: {rf_random_search.best_params_}\")\n",
        "print(f\"Melhor ROC AUC (CV): {rf_random_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_evaluation"
      },
      "source": [
        "## 7. Avaliação Final no Conjunto de Teste\n",
        "\n",
        "Os modelos otimizados são avaliados no conjunto de teste para obter uma estimativa não enviesada do desempenho. Esta etapa é crucial para verificar a capacidade de generalização dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_evaluation"
      },
      "outputs": [],
      "source": [
        "# === Avaliação Final no Conjunto de Teste ===\n",
        "print(\"=== AVALIAÇÃO FINAL NO CONJUNTO DE TESTE ===\")\n",
        "\n",
        "# Modelos otimizados\n",
        "optimized_models = {\n",
        "    'Regressão Logística Otimizada': lr_grid_search.best_estimator_,\n",
        "    'Random Forest Otimizado': rf_random_search.best_estimator_\n",
        "}\n",
        "\n",
        "final_results = []\n",
        "\n",
        "for name, model in optimized_models.items():\n",
        "    # Predições no conjunto de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calcular métricas\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    final_results.append({\n",
        "        'Modelo': name,\n",
        "        'Acurácia': accuracy,\n",
        "        'F1-Score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"   Acurácia: {accuracy:.4f}\")\n",
        "    print(f\"   F1-Score: {f1:.4f}\")\n",
        "    print(f\"   ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Tabela de resultados finais\n",
        "final_results_df = pd.DataFrame(final_results).sort_values('ROC AUC', ascending=False)\n",
        "\n",
        "print(\"\\n=== RESULTADOS FINAIS NO CONJUNTO DE TESTE ===\")\n",
        "display(final_results_df.round(4))\n",
        "\n",
        "# Identificar o melhor modelo\n",
        "best_model_name = final_results_df.iloc[0]['Modelo']\n",
        "best_model = optimized_models[best_model_name]\n",
        "\n",
        "print(f\"\\nModelo selecionado: {best_model_name}\")\n",
        "print(f\"ROC AUC: {final_results_df.iloc[0]['ROC AUC']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detailed_analysis"
      },
      "source": [
        "## 8. Análise Detalhada do Modelo Final\n",
        "\n",
        "Uma análise aprofundada do modelo selecionado é conduzida, incluindo matriz de confusão, curva ROC e relatório de classificação para avaliar o desempenho em diferentes aspectos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detailed_metrics"
      },
      "outputs": [],
      "source": [
        "# === Análise Detalhada do Modelo Selecionado ===\n",
        "print(f\"=== ANÁLISE DETALHADA: {best_model_name.upper()} ===\")\n",
        "\n",
        "# Predições do modelo selecionado\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred_best,\n",
        "                          target_names=['Sem Doença', 'Com Doença']))\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(f\"                 Predito\")\n",
        "print(f\"Real      Sem    Com\")\n",
        "print(f\"Sem      {cm[0,0]:3d}    {cm[0,1]:3d}\")\n",
        "print(f\"Com      {cm[1,0]:3d}    {cm[1,1]:3d}\")\n",
        "\n",
        "# Métricas derivadas da matriz de confusão\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "sensitivity = tp / (tp + fn)  # Recall para classe positiva\n",
        "specificity = tn / (tn + fp)  # Recall para classe negativa\n",
        "precision = tp / (tp + fp)    # Precisão para classe positiva\n",
        "\n",
        "print(f\"\\nMétricas Clínicas:\")\n",
        "print(f\"   Sensibilidade (Recall): {sensitivity:.4f}\")\n",
        "print(f\"   Especificidade: {specificity:.4f}\")\n",
        "print(f\"   Precisão: {precision:.4f}\")\n",
        "print(f\"   Falsos Negativos: {fn} (pacientes doentes não detectados)\")\n",
        "print(f\"   Falsos Positivos: {fp} (pacientes saudáveis classificados como doentes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_visualizations"
      },
      "outputs": [],
      "source": [
        "# === Visualizações da Análise Final ===\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle(f'Análise de Performance: {best_model_name}', fontsize=16, y=1.02)\n",
        "\n",
        "# 1. Matriz de Confusão\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Sem Doença', 'Com Doença'],\n",
        "            yticklabels=['Sem Doença', 'Com Doença'],\n",
        "            ax=axes[0,0])\n",
        "axes[0,0].set_title('Matriz de Confusão')\n",
        "axes[0,0].set_ylabel('Valor Real')\n",
        "axes[0,0].set_xlabel('Predição')\n",
        "\n",
        "# 2. Curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba_best)\n",
        "roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "axes[0,1].plot(fpr, tpr, color='darkorange', lw=2,\n",
        "               label=f'ROC curve (AUC = {roc_auc_value:.4f})')\n",
        "axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "axes[0,1].set_xlim([0.0, 1.0])\n",
        "axes[0,1].set_ylim([0.0, 1.05])\n",
        "axes[0,1].set_xlabel('Taxa de Falsos Positivos')\n",
        "axes[0,1].set_ylabel('Taxa de Verdadeiros Positivos')\n",
        "axes[0,1].set_title('Curva ROC')\n",
        "axes[0,1].legend(loc='lower right')\n",
        "\n",
        "# 3. Distribuição das Probabilidades\n",
        "axes[1,0].hist(y_proba_best[y_test == 0], bins=15, alpha=0.7,\n",
        "               label='Sem Doença', color='lightblue', density=True)\n",
        "axes[1,0].hist(y_proba_best[y_test == 1], bins=15, alpha=0.7,\n",
        "               label='Com Doença', color='lightcoral', density=True)\n",
        "axes[1,0].set_xlabel('Probabilidade Predita')\n",
        "axes[1,0].set_ylabel('Densidade')\n",
        "axes[1,0].set_title('Distribuição das Probabilidades')\n",
        "axes[1,0].legend()\n",
        "axes[1,0].axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Threshold')\n",
        "\n",
        "# 4. Comparação de Modelos (ROC AUC)\n",
        "model_names = final_results_df['Modelo'].str.replace(' Otimizada', '').str.replace(' Otimizado', '')\n",
        "roc_scores = final_results_df['ROC AUC']\n",
        "\n",
        "bars = axes[1,1].bar(range(len(model_names)), roc_scores,\n",
        "                     color=['gold' if i == 0 else 'lightblue' for i in range(len(model_names))])\n",
        "axes[1,1].set_xlabel('Modelos')\n",
        "axes[1,1].set_ylabel('ROC AUC')\n",
        "axes[1,1].set_title('Comparação Final de Modelos')\n",
        "axes[1,1].set_xticks(range(len(model_names)))\n",
        "axes[1,1].set_xticklabels(model_names, rotation=45)\n",
        "axes[1,1].set_ylim([0.8, 1.0])\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for i, (bar, score) in enumerate(zip(bars, roc_scores)):\n",
        "    axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "                   f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## 9. Conclusões e Discussão\n",
        "\n",
        "### Principais Resultados\n",
        "\n",
        "O projeto desenvolveu um modelo de Machine Learning para predição de doenças cardíacas.\n",
        "\n",
        "- **Modelo Final:** Regressão Logística Otimizada\n",
        "- **Performance no Teste:** Acurácia de 86.9%, ROC AUC de 0.9589\n",
        "- **Sensibilidade:** 89.3% (baixa taxa de falsos negativos)\n",
        "- **Especificidade:** 84.8% (capacidade adequada de identificar pacientes saudáveis)\n",
        "\n",
        "### Insights Técnicos\n",
        "\n",
        "A análise comparativa dos modelos revelou que a Regressão Logística, após otimização de hiperparâmetros, apresentou desempenho superior ao Random Forest. Este resultado demonstra que para datasets de tamanho moderado com features bem selecionadas, modelos lineares podem ser mais eficazes que algoritmos ensemble complexos.\n",
        "\n",
        "O dataset Heart Disease Cleveland mostrou-se adequado para a tarefa, apresentando distribuição bem balanceada das classes (ratio: 0.848) e apenas 6 valores ausentes em 303 instâncias. A validação cruzada estratificada confirmou a estabilidade dos resultados.\n",
        "\n",
        "### Relevância Clínica\n",
        "\n",
        "O modelo apresenta características importantes para aplicação médica. A alta sensibilidade (89.3%) minimiza o risco de não detectar pacientes com doença cardíaca, aspecto crítico em aplicações de saúde. A especificidade de 84.8% indica capacidade adequada de identificar corretamente pacientes saudáveis.\n",
        "\n",
        "A interpretabilidade da Regressão Logística permite compreender quais fatores contribuem mais para o diagnóstico, aspecto valioso para a prática clínica. A eficiência computacional do modelo o torna viável para implementação em sistemas de saúde.\n",
        "\n",
        "### Comparação com a Literatura\n",
        "\n",
        "Os resultados obtidos (ROC AUC = 0.9589) são consistentes e competitivos com estudos publicados utilizando o mesmo dataset. A literatura reporta valores de ROC AUC entre 0.85 e 0.95 para modelos de classificação de doenças cardíacas no dataset Cleveland.\n",
        "\n",
        "### Limitações e Trabalhos Futuros\n",
        "\n",
        "O dataset contém 303 instâncias, que embora seja o padrão na literatura, representa uma limitação para generalização. Modelos treinados em datasets maiores e mais diversos poderiam apresentar melhor capacidade de generalização.\n",
        "\n",
        "A validação externa em dados de outras instituições seria necessária para confirmar a robustez do modelo. Uma análise mais detalhada da importância das features poderia gerar insights clínicos adicionais.\n",
        "\n",
        "### Impacto e Aplicação\n",
        "\n",
        "O modelo desenvolvido pode servir como ferramenta de triagem para identificação rápida de pacientes de alto risco, apoio à decisão clínica na interpretação de dados clínicos, e sistema de alerta integrado a prontuários eletrônicos.\n",
        "\n",
        "O projeto demonstra a aplicabilidade de técnicas de Machine Learning em problemas de saúde, seguindo rigorosamente as melhores práticas de desenvolvimento e avaliação de modelos. Os resultados são consistentes com a literatura científica e indicam potencial para aplicação prática."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}